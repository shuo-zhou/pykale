{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PyKale Tutorial: Domain Adaptation on Digits with Lightning\r\n",
    "\r\n",
    "| [Open in Colab](https://colab.research.google.com/github/pykale/pykale/blob/main/examples/digits_dann_lightn/tutorial.ipynb) | [Launch Binder](https://mybinder.org/v2/gh/pykale/pykale/HEAD?filepath=examples%2Fdigits_dann_lightn%2Ftutorial.ipynb) |\r\n",
    "\r\n",
    "This tutorial is constructed based on the `digits_dann_lightn` example `main.py`, which is in turn refactored from the [ADA: (Yet) Another Domain Adaptation library](https://github.com/criteo-research/pytorch-ada).\r\n",
    "\r\n",
    "It has been put together to run interactively on online hosting platofrms including [Google Colab](https://colab.research.google.com) or [myBinder](https://mybinder.org), but can also be downloaded and run locally. Follow the [PyKale installation instructions](https://pykale.readthedocs.io/en/latest/installation.html) for this.\r\n",
    "\r\n",
    "[Domain Adaptation](https://en.wikipedia.org/wiki/Domain_adaptation) takes a model trained and evaluated on one set of data (the source) and adapts it to another (the target). In this tutorial, a model is trained on one Digits Dataset (source) and adapted to another (target)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "The first few blocks of code are necessary to set up the notebook execution environment and import the required modules, including PyKale.\n",
    "\n",
    "This checks if the notebook is running on Google Colab and installs required packages."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if 'google.colab' in str(get_ipython()):\r\n",
    "    print('Running on CoLab')\r\n",
    "    !pip install git+https://github.com/pykale/pykale.git\r\n",
    "\r\n",
    "    !git clone https://github.com/pykale/pykale.git\r\n",
    "    %cd pykale/examples/digits_dann_lightn\r\n",
    "else:\r\n",
    "    print('Not running on CoLab')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This imports required modules."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import logging\r\n",
    "import os\r\n",
    "\r\n",
    "from config import get_cfg_defaults\r\n",
    "import numpy as np\r\n",
    "import pytorch_lightning as pl\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torch.utils.data import SequentialSampler\r\n",
    "import torchvision\r\n",
    "\r\n",
    "from model import get_model\r\n",
    "\r\n",
    "from kale.loaddata.digits_access import DigitDataset\r\n",
    "from kale.loaddata.multi_domain import MultiDomainDatasets\r\n",
    "from kale.utils.csv_logger import setup_logger\r\n",
    "from kale.utils.seed import set_seed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuration\n",
    "\n",
    "In this tutorial we provide a [default configuration for domain adaptation problems](https://github.com/pykale/pykale/blob/main/examples/digits_dann_lightn/config.py), which is tailored using a [`.yaml` file for the specific application in this tutorial](https://github.com/pykale/pykale/blob/main/examples/digits_dann_lightn/configs/TUTORIAL.yaml).\n",
    "\n",
    "If GPUs are to be used at runtime, this is specified using a separate variable. If you are running this tutorial on Google Colab, or on a machine with GPU support, you might [set this](https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#trainer-class-api) to make use of GPU acceleration. (On Google Colab click Runtime->Manage Sessions and select GPU, then change to `gpus = 1`).\n",
    "\n",
    "The configuration is summarized below the following cell."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cfg_path = \"./configs/tutorial.yaml\" # Path to `.yaml` config file\r\n",
    "gpus = None # GPU settings\r\n",
    "\r\n",
    "cfg = get_cfg_defaults()\r\n",
    "cfg.merge_from_file(cfg_path)\r\n",
    "cfg.freeze()\r\n",
    "print(cfg)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup Output\n",
    "\n",
    "If you are running online in myBinder ot Google Colab, you will not have easy access to files output by this tutorial. However, if you are running locally, a folder will be created to store model training output logs, which are configured below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.makedirs(cfg.OUTPUT.DIR, exist_ok=True)\r\n",
    "format_str = \"@%(asctime)s %(name)s [%(levelname)s] - (%(message)s)\"\r\n",
    "logging.basicConfig(format=format_str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Select Datasets\n",
    "\n",
    "Source and target datasets are specified using `DigitDataset.get_source_target` from values in the configuration (`cfg`) above. In this tutorial, we specify a subset of classes (1, 3 and 8) to make training and testing quicker."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "source, target, num_channels = DigitDataset.get_source_target(\r\n",
    "    DigitDataset(cfg.DATASET.SOURCE.upper()), DigitDataset(cfg.DATASET.TARGET.upper()), cfg.DATASET.ROOT\r\n",
    ")\r\n",
    "\r\n",
    "class_subset = [1, 3, 8]\r\n",
    "\r\n",
    "dataset = MultiDomainDatasets(\r\n",
    "    source,\r\n",
    "    target,\r\n",
    "    config_weight_type=cfg.DATASET.WEIGHT_TYPE,\r\n",
    "    config_size_type=cfg.DATASET.SIZE_TYPE,\r\n",
    "    val_split_ratio=cfg.DATASET.VAL_SPLIT_RATIO,\r\n",
    "    class_ids=class_subset,\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set Seed\n",
    "\n",
    "Some algorithms used in model training require generation of pseudo-random numbers. Setting the seed from which these are generated ensures reproducibility."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "seed = cfg.SOLVER.SEED\r\n",
    "# seed_everything in pytorch_lightning did not set torch.backends.cudnn\r\n",
    "set_seed(seed)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup Model\n",
    "\n",
    "Here, we use the previously defined configuration and dataset to set up the model we will subsequently train."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%time model, train_params = get_model(cfg, dataset, num_channels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Output reports on data file use."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup Logger\n",
    "\n",
    "A logger is used to store output generated during and after model training. This information can be used to assess the effectiveness of the training and to identify problems."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "logger, results, checkpoint_callback, test_csv_file = setup_logger(\n",
    "    train_params, cfg.OUTPUT.DIR, cfg.DAN.METHOD, seed\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup Trainer\n",
    "\n",
    "A trainer object is used to determine and store model parameters. Here, one is configured with information on how a model should be trained, and what hardware will be used."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer = pl.Trainer(\n",
    "    progress_bar_refresh_rate=cfg.OUTPUT.PB_FRESH,  # in steps\n",
    "    min_epochs=cfg.SOLVER.MIN_EPOCHS,\n",
    "    max_epochs=cfg.SOLVER.MAX_EPOCHS,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=False,\n",
    "    gpus=gpus)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Output reports on available GPU and TPU resources."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Model\n",
    "\n",
    "Optimize model parameters using the trainer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%time trainer.fit(model)\n",
    "results.update(\n",
    "    is_validation=True, method_name=cfg.DAN.METHOD, seed=seed, metric_values=trainer.callback_metrics,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Optimized Model\n",
    "\n",
    "Check performance of model optmized with training data against test data which was not used in training."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# test scores\n",
    "%time trainer.test()\n",
    "results.update(\n",
    "    is_validation=False, method_name=cfg.DAN.METHOD, seed=seed, metric_values=trainer.callback_metrics,\n",
    ")\n",
    "results.print_scores(cfg.DAN.METHOD)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Outputs are defined as:\n",
    "\n",
    "* 'Te_domain_acc': Accuracy on classifying the domain (source or target) from which data came.\n",
    "* 'Te_source_acc': Accuracy on test data drawn from the source dataset.\n",
    "* 'Te_target_acc': Accuracy on test data drawn from the target dataset.\n",
    "* 'test_loss': Loss function value on the test data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Store Log"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results.to_csv(test_csv_file)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
